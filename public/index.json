[{"content":"My CV Click the link below to view my CV directly in your browser:\nView CV\n","permalink":"http://localhost:1313/cv/","summary":"\u003ch1 id=\"my-cv\"\u003eMy CV\u003c/h1\u003e\n\u003cp\u003eClick the link below to view my CV directly in your browser:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://kerembuekrue.github.io/public/cv/cv.pdf\"\u003eView CV\u003c/a\u003e\u003c/p\u003e","title":"Curriculum Vitae"},{"content":"My First Blog Post Welcome to my blog! In this post, I will share insights about the intersection of Bayesian learning and quantum circuits.\nKey Insights Bayesian Learning: A robust framework for modeling uncertainty in predictions. Quantum Circuits: Leveraging quantum mechanics to perform calculations faster than classical computers. Stay tuned for more updates as I explore these fascinating topics!\n","permalink":"http://localhost:1313/blog/blog1/","summary":"\u003ch1 id=\"my-first-blog-post\"\u003eMy First Blog Post\u003c/h1\u003e\n\u003cp\u003eWelcome to my blog! In this post, I will share insights about the intersection of Bayesian learning and quantum circuits.\u003c/p\u003e\n\u003ch2 id=\"key-insights\"\u003eKey Insights\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBayesian Learning\u003c/strong\u003e: A robust framework for modeling uncertainty in predictions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eQuantum Circuits\u003c/strong\u003e: Leveraging quantum mechanics to perform calculations faster than classical computers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStay tuned for more updates as I explore these fascinating topics!\u003c/p\u003e","title":"First Blog Post"},{"content":" Quantum Kernels Quantum kernels leverage the principles of quantum computing to enhance machine learning algorithms, particularly in the context of kernel methods. The primary objective of this research project is to analyze data more efficiently using quantum algorithms compared to classical approaches.\nKey Concepts Quantum Kernel Function: The quantum kernel can be expressed as:\n$$ K(x, y) = \\langle \\psi(x) | \\psi(y) \\rangle $$\nwhere (|\\psi(x)\\rangle) and (|\\psi(y)\\rangle) are quantum states corresponding to the classical data points (x) and (y).\nPerformance Enhancement: Quantum kernels can potentially provide exponential speedups in certain problems, allowing for the analysis of high-dimensional data that is intractable for classical methods.\nTechnologies: This project utilizes Python and Qiskit for implementing quantum algorithms and experimenting with quantum kernel methods.\nGitHub Repository: Project 2 Repository\nDeep Gaussian Processes Deep Gaussian Processes (DGPs) extend the standard Gaussian Process (GP) framework by allowing multiple layers of GPs to model complex functions. This approach is particularly effective in capturing intricate relationships within data, making it suitable for various machine learning tasks.\nKey Concepts Gaussian Process Prior: A GP is defined by a mean function and a covariance function, typically expressed as:\n$$ f(x) \\sim \\mathcal{GP}(m(x), k(x, x\u0026rsquo;)) $$\nwhere (m(x)) is the mean function and (k(x, x\u0026rsquo;)) is the covariance function.\nDeep Architecture: In a DGP, multiple GPs are stacked to form a hierarchical model, allowing for more expressive representations of the data:\n$$ f^{(l)}(x) \\sim \\mathcal{GP}(m^{(l)}(x), k^{(l)}(x, x\u0026rsquo;)) $$\nfor each layer (l), where the output of one layer serves as the input to the next.\nApplications: DGPs can be applied in regression, classification, and other tasks where capturing uncertainty and complex patterns in data is crucial.\nTechnologies: This project also employs Python and Qiskit to implement and analyze DGPs in the context of quantum computing.\nGitHub Repository: Project 2 Repository\n","permalink":"http://localhost:1313/projects/project2/","summary":"\u003cscript src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"\u003e\u003c/script\u003e\n\u003cscript id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\u003e\u003c/script\u003e\n\u003ch3 id=\"quantum-kernels\"\u003eQuantum Kernels\u003c/h3\u003e\n\u003cp\u003eQuantum kernels leverage the principles of quantum computing to enhance machine learning algorithms, particularly in the context of kernel methods. The primary objective of this research project is to analyze data more efficiently using quantum algorithms compared to classical approaches.\u003c/p\u003e\n\u003ch4 id=\"key-concepts\"\u003eKey Concepts\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eQuantum Kernel Function\u003c/strong\u003e: The quantum kernel can be expressed as:\u003c/p\u003e\n\u003cp\u003e$$\nK(x, y) = \\langle \\psi(x) | \\psi(y) \\rangle\n$$\u003c/p\u003e","title":"Quantum Kernels for Deep Gaussian Processes"},{"content":"My Second Blog Post Welcome to my blog! In this post, I will share insights about the intersection of Bayesian learning and quantum circuits.\nKey Insights Bayesian Learning: A robust framework for modeling uncertainty in predictions. Quantum Circuits: Leveraging quantum mechanics to perform calculations faster than classical computers. Stay tuned for more updates as I explore these fascinating topics!\n","permalink":"http://localhost:1313/blog/blog2/","summary":"\u003ch1 id=\"my-second-blog-post\"\u003eMy Second Blog Post\u003c/h1\u003e\n\u003cp\u003eWelcome to my blog! In this post, I will share insights about the intersection of Bayesian learning and quantum circuits.\u003c/p\u003e\n\u003ch2 id=\"key-insights\"\u003eKey Insights\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eBayesian Learning\u003c/strong\u003e: A robust framework for modeling uncertainty in predictions.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eQuantum Circuits\u003c/strong\u003e: Leveraging quantum mechanics to perform calculations faster than classical computers.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eStay tuned for more updates as I explore these fascinating topics!\u003c/p\u003e","title":"Second Blog Post"},{"content":" Variational Quantum Linear Solver (VQLS) Motivation Solving linear systems of equations is a fundamental task in many applications, including machine learning. Given a linear system problem ( A x = b ), where ( A \\in \\mathbb{R}^{N \\times N} ) and ( b \\in \\mathbb{R}^N ), the goal is to find the solution vector ( x \\in \\mathbb{R}^N ). Traditional methods like matrix inversion yield the solution as ( x = A^{-1} b ), but this approach has a computational complexity of ( \\mathcal{O}(N^3) ), making it impractical for large ( N ).\nQuantum algorithms offer a promising alternative for large-scale computations, with some providing exponential (e.g., Shor\u0026rsquo;s algorithm) or quadratic speedup (e.g., Grover\u0026rsquo;s algorithm). Harrow, Hassidim, and Lloyd developed a fully quantum algorithm for solving linear systems that achieves exponential speedup, characterized by a complexity of:\n$$ \\mathcal{O}\\left(\\log(N) s^2 \\kappa^2 / \\epsilon\\right) $$\nwhere ( s ) is sparsity, ( \\kappa ) is the condition number, and ( \\epsilon ) is the desired precision. However, this algorithm requires a quantum computer with a large number of error-corrected qubits, which is currently unattainable.\nToday, we are in the Noisy Intermediate-Scale Quantum (NISQ) era, where a few hundred qubits with error mitigation can be utilized for small-scale quantum computations. Variational Quantum Algorithms (VQA) present promising near-term applications, combining classical and quantum algorithms to solve computational tasks.\nOverview of VQLS The Variational Quantum Linear Solver (VQLS) was introduced by Bravo-Prieto et al. as a hybrid quantum-classical algorithm suitable for NISQ applications. The system matrix ( A ) is decomposed into a linear combination of unitaries:\n$$ A = \\sum_{l=0}^{L} c_l A_l $$\nThe goal is to find a quantum state ( A|x\\rangle ) that is proportional to ( b ). A Parametrized Quantum Circuit (PQC) is utilized, consisting of a gate sequence ( V(\\theta) ) with optimizable parameters ( \\theta ). The state ( |x(\\theta)\\rangle = V(\\theta) |0\\rangle ) is prepared starting from the ground state ( |0\\rangle ).\nTo quantify how close the state ( A|x\\rangle ) is to ( b ), a local cost function is defined, where a value of ( 0 ) indicates that the linear system is solved. The cost function ( C(\\theta) ) is minimized until it reaches a threshold value ( C(\\theta) \\leq \\epsilon ). After executing the algorithm, the optimized parameters ( \\theta_{\\rm opt} ) can be used to prepare the solution state ( |x(\\theta_{\\rm opt})\\rangle ).\nCost Function Global Cost Function One potential global cost function is the overlap between the projector ( |\\psi\\rangle\\langle \\psi | ) with ( |\\psi\\rangle = A |x\\rangle ) and the subspace orthogonal to the state ( |b\\rangle ):\n$$ \\bar{C}_G = \\text{Tr}(|\\psi\\rangle\\langle\\psi|(\\mathbb{I} - |b\\rangle\\langle b|)) = \\langle x | H_G | x \\rangle $$\nwhere the Hamiltonian ( H_G ) is defined as:\n$$ H_G = A^\\dagger (\\mathbb{I} - |b\\rangle \\langle b |)A $$\nThis cost function is small if ( |\\psi\\rangle \\propto |b\\rangle ) (the solution) or if the norm of ( |\\psi\\rangle ) is small, which can make it size-dependent. To overcome this, an alternative cost function is proposed:\n$$ C_G = \\frac{\\bar{C}_G}{\\langle \\psi | \\psi \\rangle} = 1 - |\\langle b | \\Psi \\rangle |^2 $$\nwhere ( |\\Psi\\rangle=|\\psi\\rangle/\\langle \\psi | \\psi \\rangle ).\nLocal Cost Function Global cost functions can lead to barren plateaus, where the gradient of the cost function vanishes exponentially with the number of qubits. A local cost function is defined as:\n$$ \\bar{C}_L = \\langle x | H_L | x \\rangle , \\qquad C_L = \\frac{\\bar{C}_L}{\\langle \\psi | \\psi \\rangle} $$\nwith the alternative Hamiltonian given by:\n$$ H_L = A^\\dagger U \\left( \\mathbb{I} - \\frac{1}{n} \\sum_{j=0}^{n-1} |0_j\\rangle \\langle 0_j| \\otimes \\mathbb{I}_{\\bar{j}}\\right) U^\\dagger A $$\nBy reformulating this local Hamiltonian using the relation ( |0\\rangle \\langle 0 | = (\\mathbb{I} + Z)/2 ) and the parametrized state ( |x\\rangle = V(\\theta) | 0 \\rangle ), the cost function can be expressed as:\n$$ C_L = \\frac{1}{2} - \\frac{1}{2n} \\frac{\\sum_{j} \\sum_{ll\u0026rsquo;} c_l c_{l\u0026rsquo;}^* \\langle 0 | V^\\dagger A_{l\u0026rsquo;}^\\dagger U Z_j U^\\dagger A_l V | 0 \\rangle}{\\sum_{ll\u0026rsquo;} c_l c_{l\u0026rsquo;}^*\\langle 0 | V^\\dagger A_{l\u0026rsquo;}^\\dagger A_l V|0 \\rangle} $$\nThis can be simplified using the compact notation:\n$$ \\beta_{ll\u0026rsquo;} = \\langle 0 | V^\\dagger A_{l\u0026rsquo;}^\\dagger A_l V | 0 \\rangle , , \\quad \\quad \\delta_{ll\u0026rsquo;}^{(j)} = \\langle 0 | V^\\dagger A_{l\u0026rsquo;}^\\dagger U Z_j U^\\dagger A_l V | 0 \\rangle $$\nThe final form of the cost function is:\n$$ C_L = \\frac{1}{2} - \\frac{1}{2n} \\frac{\\sum_{j} \\sum_{ll\u0026rsquo;} c_l , c_{l\u0026rsquo;}^* , \\delta_{ll\u0026rsquo;}^{(j)}}{\\sum_{ll\u0026rsquo;} c_l , c_{l\u0026rsquo;}^* , \\beta_{ll\u0026rsquo;}} ,. $$\n","permalink":"http://localhost:1313/projects/project1/","summary":"\u003cscript src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"\u003e\u003c/script\u003e\n\u003cscript id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"\u003e\u003c/script\u003e\n\u003ch3 id=\"variational-quantum-linear-solver-vqls\"\u003eVariational Quantum Linear Solver (VQLS)\u003c/h3\u003e\n\u003ch4 id=\"motivation\"\u003eMotivation\u003c/h4\u003e\n\u003cp\u003eSolving linear systems of equations is a fundamental task in many applications, including machine learning. Given a linear system problem ( A x = b ), where ( A \\in \\mathbb{R}^{N \\times N} ) and ( b \\in \\mathbb{R}^N ), the goal is to find the solution vector ( x \\in \\mathbb{R}^N ). Traditional methods like matrix inversion yield the solution as ( x = A^{-1} b ), but this approach has a computational complexity of ( \\mathcal{O}(N^3) ), making it impractical for large ( N ).\u003c/p\u003e","title":"Variational Quantum Linear Solver applied to Gaussian Process Regression"},{"content":"Contact kerembuekrue@gmail.com ","permalink":"http://localhost:1313/contact/","summary":"\u003ch3 id=\"contact\"\u003eContact\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003cimg alt=\"email image\" height=\"45\" src=\"images/email.jpg\" width=\"45\"/\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: left\"\u003e\u003ca href=\"mailto:kerembuekrue@gmail.com\"\u003ekerembuekrue@gmail.com\u003c/a\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":""}]